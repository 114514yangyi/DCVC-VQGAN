{
    "model_type": "TamingVQGAN",
    "model_args": {
      "model_variant": "EMAVQ",
      "n_embed": 16384,
      "embed_dim": 512,
      "rvq_levels": 4,
      "ddconfig": {
        "double_z": false,
        "z_channels": 256,
        "resolution": 256,
        "in_channels": 3,
        "out_ch": 3,
        "ch": 128,
        "ch_mult": [1, 1, 2, 2, 4],
        "num_res_blocks": 2,
        "attn_resolutions": [16],
        "dropout": 0.0
      },
      "lossconfig": {
        "target": "models.taming.modules.losses.vqperceptual.VQLPIPSWithDiscriminator",
        "params": {
          "disc_conditional": false,
          "disc_in_channels": 3,
          "disc_start": 100000,
          "disc_weight": 0.5,
          "codebook_weight": 1.0
        }
      }
    },
    "data": {
      "use_images": true,
      "train_dir": "/data/huyang/data/train_distribute",
      "val_dir": "/data/huyang/data/vaild",
      "batch_size": 1,
      "num_workers": 4,
      "sequence_length": 8,
      "resolution": 256,
      "seed": 2025
    },
    "train": {
      "device": "cuda:5",
      "num_steps": 300000,
    "lr": 4.5e-6,
    "disc_lr": 4.5e-6,
      "log_dir": "/data/huyang/new_test/RQVAE/runs/2-logs",
      "save_dir": "/data/huyang/new_test/RQVAE/runs/2-checkpoints",
      "save_interval": 5000,
      "log_interval": 50,
      "validation_interval": 5000,
      "best_max_images": 2048,
      "resume_ckpt": null,
      "grad_accum_steps": 8
    },
    "wandb": {
      "enabled": true,
      "project": "rqvae",
      "name": "rqvae-2",
      "entity": null,
      "log_interval": 50,
      "image_interval": 500
    }
  }
  