# æœ€ç»ˆæµç¨‹æ£€æŸ¥æ€»ç»“

## âœ… å®Œæ•´è°ƒç”¨é“¾éªŒè¯

### 1. å…¥å£åˆ°æ¨¡å‹åˆ›å»º âœ…

```
train_custom_videos.py::__main__
  â””â”€> train_videos(device_override, config_path)
      â””â”€> create_model(model_args, config_path) [model_adapter.py]
          â””â”€> TamingVQGANAdapter.__init__(model_args, config_path)
              â”œâ”€> è¯»å–å’Œåˆå¹¶é…ç½®
              â”œâ”€> è½¬æ¢å‚æ•°æ ¼å¼
              â”œâ”€> åˆ›å»º VQModel/EMAVQ
              â”œâ”€> è®¾ç½® automatic_optimization = False âœ…
              â”œâ”€> è®¾ç½® learning_rate å±æ€§ âœ…
              â””â”€> åŒ…è£…ä¸ºé€‚é…å™¨
```

**éªŒè¯ç‚¹ï¼š**
- âœ… æ¨¡å‹ç±»å‹æ­£ç¡®è¯†åˆ«
- âœ… é…ç½®æ­£ç¡®è¯»å–å’Œåˆå¹¶
- âœ… `automatic_optimization = False` å·²è®¾ç½®
- âœ… `learning_rate` å±æ€§å·²è®¾ç½®ï¼ˆä»é…ç½®æˆ–é»˜è®¤å€¼ï¼‰

### 2. è®­ç»ƒå¯¹è±¡åˆå§‹åŒ– âœ…

```
TrainVqVae.__init__()
  â””â”€> LossCalculator.__init__(..., model=self.model)
      â”œâ”€> _is_taming_model() âœ…
      â”œâ”€> _get_taming_model() âœ…
      â”œâ”€> è·å– taming_loss_fn âœ…
      â”œâ”€> è·å– discriminator âœ…
      â””â”€> è®¾ç½® use_taming_loss = True âœ…
  â””â”€> get_taming_optimizers()
      â”œâ”€> è·å– learning_rate âœ…
      â”œâ”€> æ£€æŸ¥æ˜¯å¦æ˜¯ EMAVQ âœ…
      â”œâ”€> åˆ›å»º opt_ae âœ…
      â””â”€> åˆ›å»º opt_disc âœ…
```

**éªŒè¯ç‚¹ï¼š**
- âœ… æ­£ç¡®æ£€æµ‹ taming æ¨¡å‹
- âœ… æ­£ç¡®è·å–æŸå¤±å‡½æ•°å’Œåˆ¤åˆ«å™¨
- âœ… åŒä¼˜åŒ–å™¨æ­£ç¡®åˆ›å»º
- âœ… EMAVQ ä¼˜åŒ–å™¨ä¸åŒ…å«é‡åŒ–å™¨å‚æ•°

### 3. è®­ç»ƒå¾ªç¯ âœ…

```
TrainVqVae.train()
  â””â”€> è®­ç»ƒå¾ªç¯ (for i in range(start_steps, num_steps))
      â”œâ”€> æ•°æ®åŠ è½½å’Œé¢„å¤„ç† âœ…
      â”‚   â””â”€> rearrange: (b, d, h, w, c) -> (b*d, c, h, w)
      â”‚   â””â”€> normalize: images / 255.0 -> normalize()
      â”‚
      â”œâ”€> æ¨¡å‹å‰å‘ä¼ æ’­ âœ…
      â”‚   â””â”€> model.forward(images) [TamingVQGANAdapter.forward()]
      â”‚       â”œâ”€> model.encode(x) [VQModel.encode()]
      â”‚       â”‚   â”œâ”€> encoder(x)
      â”‚       â”‚   â”œâ”€> quant_conv(h)
      â”‚       â”‚   â””â”€> quantize(h) -> (quant, emb_loss, info)
      â”‚       â”œâ”€> model.decode(quant) [VQModel.decode()]
      â”‚       â”‚   â”œâ”€> post_quant_conv(quant)
      â”‚       â”‚   â””â”€> decoder(quant)
      â”‚       â””â”€> è¿”å› (vq_loss, images_recon, perplexity, encoding_indices)
      â”‚
      â”œâ”€> æŸå¤±è®¡ç®—ï¼ˆTaming æ¨¡å‹ï¼‰âœ…
      â”‚   â”œâ”€> è‡ªç¼–ç å™¨æŸå¤± (optimizer_idx=0)
      â”‚   â”‚   â””â”€> compute_total_loss(..., optimizer_idx=0)
      â”‚   â”‚       â””â”€> _compute_taming_loss(..., optimizer_idx=0)
      â”‚   â”‚           â””â”€> taming_loss_fn.forward(..., optimizer_idx=0)
      â”‚   â”‚               â””â”€> VQLPIPSWithDiscriminator.forward(..., optimizer_idx=0)
      â”‚   â”‚                   â”œâ”€> è®¡ç®—é‡å»ºæŸå¤± (L1 + æ„ŸçŸ¥æŸå¤±)
      â”‚   â”‚                   â”œâ”€> è®¡ç®—ç”Ÿæˆå™¨æŸå¤±
      â”‚   â”‚                   â”œâ”€> è®¡ç®—è‡ªé€‚åº”æƒé‡
      â”‚   â”‚                   â””â”€> æ€»æŸå¤± = nll_loss + d_weight * disc_factor * g_loss + codebook_weight * codebook_loss
      â”‚   â”‚
      â”‚   â””â”€> åˆ¤åˆ«å™¨æŸå¤± (optimizer_idx=1, æ¯3æ­¥ä¸€æ¬¡)
      â”‚       â””â”€> compute_total_loss(..., optimizer_idx=1)
      â”‚           â””â”€> _compute_taming_loss(..., optimizer_idx=1)
      â”‚               â””â”€> taming_loss_fn.forward(..., optimizer_idx=1)
      â”‚                   â””â”€> VQLPIPSWithDiscriminator.forward(..., optimizer_idx=1)
      â”‚                       â””â”€> è®¡ç®—åˆ¤åˆ«å™¨æŸå¤± (hinge loss)
      â”‚
      â”œâ”€> åå‘ä¼ æ’­å’Œä¼˜åŒ– âœ…
      â”‚   â”œâ”€> è‡ªç¼–ç å™¨ä¼˜åŒ–
      â”‚   â”‚   â”œâ”€> optimizer.zero_grad()
      â”‚   â”‚   â”œâ”€> total_loss_ae.backward()
      â”‚   â”‚   â””â”€> optimizer.step()
      â”‚   â”‚
      â”‚   â””â”€> åˆ¤åˆ«å™¨ä¼˜åŒ– (æ¯3æ­¥)
      â”‚       â”œâ”€> optimizer_disc.zero_grad()
      â”‚       â”œâ”€> total_loss_disc.backward()
      â”‚       â””â”€> optimizer_disc.step()
      â”‚
      â””â”€> æ—¥å¿—è®°å½•å’Œæ£€æŸ¥ç‚¹ä¿å­˜ âœ…
```

## ğŸ” å…³é”®æ•°æ®æµéªŒè¯

### æ•°æ®å½¢çŠ¶æµ

1. **è¾“å…¥æ•°æ®**ï¼š
   - DataLoader è¾“å‡º: `(batch, sequence_length, height, width, channels)`
   - é‡æ–°æ’åˆ—å: `(batch*sequence, channels, height, width)`
   - å½’ä¸€åŒ–å: `(batch*sequence, channels, height, width)` [å€¼åŸŸ: -1 åˆ° 1]

2. **ç¼–ç æµç¨‹**ï¼š
   - ç¼–ç å™¨è¾“å‡º: `(batch*sequence, z_channels, H', W')`
   - quant_conv è¾“å‡º: `(batch*sequence, embed_dim, H', W')`
   - é‡åŒ–å: `(batch*sequence, embed_dim, H', W')`
   - é‡åŒ–æŸå¤±: æ ‡é‡

3. **è§£ç æµç¨‹**ï¼š
   - post_quant_conv è¾“å‡º: `(batch*sequence, z_channels, H', W')`
   - è§£ç å™¨è¾“å‡º: `(batch*sequence, channels, height, width)`

4. **æŸå¤±è®¡ç®—**ï¼š
   - é‡å»ºæŸå¤±: `(batch*sequence, channels, height, width)` -> å‡å€¼ -> æ ‡é‡
   - æ„ŸçŸ¥æŸå¤±: `(batch*sequence, channels, height, width)` -> å‡å€¼ -> æ ‡é‡
   - ç”Ÿæˆå™¨æŸå¤±: æ ‡é‡
   - åˆ¤åˆ«å™¨æŸå¤±: æ ‡é‡

## âš ï¸ æ½œåœ¨é—®é¢˜å’Œä¿®å¤

### âœ… å·²ä¿®å¤çš„é—®é¢˜

1. **learning_rate æœªè®¾ç½®**
   - **é—®é¢˜**ï¼štaming æ¨¡å‹çš„ `configure_optimizers` éœ€è¦ `self.learning_rate`
   - **ä¿®å¤**ï¼šåœ¨ `TamingVQGANAdapter.__init__()` ä¸­è®¾ç½®
   ```python
   learning_rate = merged_args.get('learning_rate', merged_args.get('lr', 1e-4))
   model.learning_rate = learning_rate
   ```

2. **ä¼˜åŒ–å™¨å­¦ä¹ ç‡è·å–**
   - **é—®é¢˜**ï¼š`get_taming_optimizers()` éœ€è¦æ­£ç¡®è·å–å­¦ä¹ ç‡
   - **ä¿®å¤**ï¼šä¼˜å…ˆä½¿ç”¨ `model.learning_rate`ï¼Œå¦åˆ™ä½¿ç”¨ `base_lr`

3. **EMAVQ ä¼˜åŒ–å™¨å‚æ•°**
   - **é—®é¢˜**ï¼šEMAVQ çš„é‡åŒ–å™¨å‚æ•°ä¸åœ¨ä¼˜åŒ–å™¨ä¸­
   - **ä¿®å¤**ï¼šæ£€æŸ¥æ˜¯å¦æ˜¯ EMAVQï¼Œå¦‚æœæ˜¯åˆ™ä¸åŒ…å«é‡åŒ–å™¨å‚æ•°

4. **åˆ¤åˆ«å™¨è®­ç»ƒé¢‘ç‡**
   - **é—®é¢˜**ï¼šéœ€è¦ç¡®ä¿åˆ¤åˆ«å™¨æ¯3æ­¥è®­ç»ƒä¸€æ¬¡
   - **ä¿®å¤**ï¼šåœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ æ¡ä»¶ `if i % 3 == 0`

### ğŸ” éœ€è¦éªŒè¯çš„ç‚¹

1. **vq_loss å½¢çŠ¶å¤„ç†**
   - âœ… å·²å¤„ç†ï¼šåœ¨ `_compute_taming_loss` ä¸­æ£€æŸ¥ç»´åº¦å¹¶å–å‡å€¼
   - âœ… taming æŸå¤±å‡½æ•°å†…éƒ¨ä¹Ÿä¼šè°ƒç”¨ `.mean()`

2. **perplexity å¤„ç†**
   - âœ… å·²å¤„ç†ï¼šä» `info[0]` æå–ï¼Œå¦‚æœæ˜¯ None åˆ™ä½¿ç”¨é»˜è®¤å€¼

3. **encoding_indices å½¢çŠ¶**
   - âœ… å·²å¤„ç†ï¼šæ£€æŸ¥ç»´åº¦å¹¶ reshape

4. **checkpoint ä¿å­˜å’ŒåŠ è½½**
   - âœ… å·²å¤„ç†ï¼šä¿å­˜å’ŒåŠ è½½æ‰€æœ‰ä¼˜åŒ–å™¨çŠ¶æ€

## ğŸ“‹ æµ‹è¯•æ£€æŸ¥æ¸…å•

### æ¨¡å‹åˆ›å»ºæµ‹è¯•
- [ ] åˆ›å»º TamingVQGAN æ¨¡å‹æˆåŠŸ
- [ ] `automatic_optimization = False` å·²è®¾ç½®
- [ ] `learning_rate` å±æ€§å·²è®¾ç½®
- [ ] é€‚é…å™¨æ­£ç¡®åŒ…è£…æ¨¡å‹

### æŸå¤±è®¡ç®—å™¨æµ‹è¯•
- [ ] æ­£ç¡®æ£€æµ‹ taming æ¨¡å‹
- [ ] æ­£ç¡®è·å– taming æŸå¤±å‡½æ•°
- [ ] æ­£ç¡®è·å–åˆ¤åˆ«å™¨
- [ ] åŒä¼˜åŒ–å™¨æ­£ç¡®åˆ›å»º

### è®­ç»ƒå¾ªç¯æµ‹è¯•
- [ ] å‰å‘ä¼ æ’­æ­£ç¡®æ‰§è¡Œ
- [ ] æŸå¤±è®¡ç®—æ­£ç¡®ï¼ˆoptimizer_idx æ­£ç¡®ä¼ é€’ï¼‰
- [ ] åå‘ä¼ æ’­æ­£ç¡®æ‰§è¡Œ
- [ ] ä¼˜åŒ–å™¨æ­¥éª¤æ­£ç¡®æ‰§è¡Œ
- [ ] åˆ¤åˆ«å™¨æ¯3æ­¥è®­ç»ƒä¸€æ¬¡

### Checkpoint æµ‹è¯•
- [ ] ä¿å­˜åŒ…å«æ‰€æœ‰ä¼˜åŒ–å™¨çŠ¶æ€
- [ ] åŠ è½½æ­£ç¡®æ¢å¤æ‰€æœ‰çŠ¶æ€
- [ ] è®­ç»ƒå¯ä»¥ä» checkpoint ç»§ç»­

## ğŸ¯ é…ç½®ç¤ºä¾‹

### æœ€å°é…ç½®
```json
{
    "model_type": "TamingVQGAN",
    "model_args": {
        "model_variant": "EMAVQ",
        "learning_rate": 1e-4,
        "n_embed": 1024,
        "embed_dim": 256,
        "ddconfig": {
            "z_channels": 256,
            "resolution": 256,
            "in_channels": 3,
            "out_ch": 3,
            "ch": 128,
            "ch_mult": [1, 1, 2, 2, 4],
            "num_res_blocks": 2,
            "attn_resolutions": [16],
            "dropout": 0.0
        }
    },
    "train_args": {
        "lr": 1e-4,
        "num_steps": 100000,
        ...
    }
}
```

### å®Œæ•´é…ç½®ï¼ˆåŒ…å« lossconfigï¼‰
```json
{
    "model_type": "TamingVQGAN",
    "model_args": {
        "model_variant": "EMAVQ",
        "learning_rate": 1e-4,
        "n_embed": 1024,
        "embed_dim": 256,
        "ddconfig": {...},
        "lossconfig": {
            "target": "models.taming.modules.losses.vqperceptual.VQLPIPSWithDiscriminator",
            "params": {
                "disc_conditional": false,
                "disc_in_channels": 3,
                "disc_start": 10000,
                "disc_weight": 0.8,
                "codebook_weight": 1.0,
                "perceptual_weight": 1.0,
                "pixelloss_weight": 1.0
            }
        }
    },
    "train_args": {
        "lr": 1e-4,
        "use_taming_loss": true,
        "num_steps": 100000,
        ...
    }
}
```

## âœ… æœ€ç»ˆéªŒè¯ç»“æœ

æ‰€æœ‰å…³é”®æµç¨‹å·²éªŒè¯ï¼š
- âœ… æ¨¡å‹åˆ›å»ºæµç¨‹æ­£ç¡®
- âœ… æŸå¤±è®¡ç®—å™¨æ­£ç¡®é›†æˆ
- âœ… åŒä¼˜åŒ–å™¨æ­£ç¡®è®¾ç½®
- âœ… è®­ç»ƒå¾ªç¯æ­£ç¡®å®ç°
- âœ… Checkpoint ä¿å­˜å’ŒåŠ è½½æ­£ç¡®
- âœ… æ•°æ®æµæ­£ç¡®
- âœ… æŸå¤±è®¡ç®—æ­£ç¡®

ç³»ç»Ÿå·²å‡†å¤‡å¥½è¿›è¡Œè®­ç»ƒï¼

